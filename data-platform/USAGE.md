# AI Data Platform ä½¿ç”¨æ–¹æ³•

## ğŸš€ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### 1. TrueNAS Scale ã§ã®å±•é–‹

```bash
# ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³
git clone <repository-url>
cd data-platform

# ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
./scripts/setup.sh
```

### 2. æ‰‹å‹•ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆè©³ç´°åˆ¶å¾¡ãŒå¿…è¦ãªå ´åˆï¼‰

```bash
# ç’°å¢ƒå¤‰æ•°è¨­å®š
cp .env.example .env
# .env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç·¨é›†ã—ã¦ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’è¨­å®š

# Docker Compose ã§ã®é–‹ç™ºç’°å¢ƒ
docker-compose up -d

# ã¾ãŸã¯ Kubernetes ã§ã®æœ¬ç•ªç’°å¢ƒ
kubectl apply -f kubernetes/
```

## ğŸ“Š ã‚¢ã‚¯ã‚»ã‚¹æ–¹æ³•

### Airflow WebUI
- URL: `http://<TrueNAS-IP>:8080`
- ãƒ¦ãƒ¼ã‚¶ãƒ¼å: `admin`
- ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰: `.env`ãƒ•ã‚¡ã‚¤ãƒ«ã®`AIRFLOW_PASSWORD`

### API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
- ãƒ™ãƒ¼ã‚¹URL: `http://<TrueNAS-IP>:8000`
- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: `http://<TrueNAS-IP>:8000/docs`
- ReDoc: `http://<TrueNAS-IP>:8000/redoc`

## ğŸ”„ ä¸»è¦ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

### 1. ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
- **DAGå**: `scraping_workflow`
- **å®Ÿè¡Œé–“éš”**: 6æ™‚é–“ã”ã¨
- **æ©Ÿèƒ½**: 
  - ç”»åƒURLã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
  - PostgreSQL/MongoDBã¸ã®ãƒ‡ãƒ¼ã‚¿ä¿å­˜
  - ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
  - å¤ã„ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

### 2. ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
- **DAGå**: `data_processing_workflow`
- **å®Ÿè¡Œé–“éš”**: 12æ™‚é–“ã”ã¨
- **æ©Ÿèƒ½**:
  - ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»çµ±è¨ˆç”Ÿæˆ
  - AIå­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™
  - ãƒ‡ãƒ¼ã‚¿å“è³ªç›£è¦–

## ğŸ”Œ APIä½¿ç”¨ä¾‹

### åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿å–å¾—

```python
import requests

# ãƒ™ãƒ¼ã‚¹URL
BASE_URL = "http://<TrueNAS-IP>:8000"

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
response = requests.get(f"{BASE_URL}/health")
print(response.json())

# ç”»åƒãƒ‡ãƒ¼ã‚¿å–å¾—
response = requests.get(f"{BASE_URL}/api/v1/images?limit=10")
images = response.json()
print(f"å–å¾—ã—ãŸç”»åƒæ•°: {len(images)}")

# ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼å–å¾—
response = requests.get(f"{BASE_URL}/api/v1/analytics/summary")
summary = response.json()
print(f"ç·ç”»åƒæ•°: {summary['total_images']}")
```

### AIå­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå–å¾—

```python
# å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå–å¾—
response = requests.get(f"{BASE_URL}/api/v1/training/dataset?limit=1000")
dataset = response.json()

structured_data = dataset['structured_data']
raw_data = dataset['raw_data']

print(f"æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿: {len(structured_data)}ä»¶")
print(f"ç”Ÿãƒ‡ãƒ¼ã‚¿: {len(raw_data)}ä»¶")
```

### ç”»åƒæ¤œç´¢

```python
# ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢
query = "çŒ«"
response = requests.get(f"{BASE_URL}/api/v1/images/search?query={query}&limit=50")
results = response.json()

for image in results:
    print(f"URL: {image['image_url']}")
    print(f"èª¬æ˜: {image['alt_text']}")
    print("---")
```

## ğŸ¤– AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé€£æº

### 1. ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

```python
class DataRetrievalAgent:
    def __init__(self, api_base_url):
        self.api_url = api_base_url
    
    def get_latest_images(self, count=100):
        """æœ€æ–°ã®ç”»åƒãƒ‡ãƒ¼ã‚¿å–å¾—"""
        response = requests.get(f"{self.api_url}/api/v1/images?limit={count}")
        return response.json()
    
    def search_images_by_keyword(self, keyword, limit=50):
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ç”»åƒæ¤œç´¢"""
        response = requests.get(
            f"{self.api_url}/api/v1/images/search",
            params={"query": keyword, "limit": limit}
        )
        return response.json()
    
    def get_training_data(self, limit=1000):
        """å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        response = requests.get(
            f"{self.api_url}/api/v1/training/dataset",
            params={"limit": limit, "include_raw": True}
        )
        return response.json()

# ä½¿ç”¨ä¾‹
agent = DataRetrievalAgent("http://<TrueNAS-IP>:8000")
images = agent.get_latest_images(50)
training_data = agent.get_training_data(1000)
```

### 2. åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

```python
class AnalyticsAgent:
    def __init__(self, api_base_url):
        self.api_url = api_base_url
    
    def get_data_insights(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ã‚µã‚¤ãƒˆå–å¾—"""
        summary = requests.get(f"{self.api_url}/api/v1/analytics/summary").json()
        daily_stats = requests.get(f"{self.api_url}/api/v1/analytics/daily-stats").json()
        
        return {
            "summary": summary,
            "trends": daily_stats,
            "recommendations": self._generate_recommendations(summary)
        }
    
    def _generate_recommendations(self, summary):
        """ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ"""
        recommendations = []
        
        if summary['data_quality_score'] < 70:
            recommendations.append("ãƒ‡ãƒ¼ã‚¿å“è³ªã®æ”¹å–„ãŒå¿…è¦ã§ã™")
        
        if summary['last_24h_count'] == 0:
            recommendations.append("éå»24æ™‚é–“ã§ãƒ‡ãƒ¼ã‚¿åé›†ãŒã‚ã‚Šã¾ã›ã‚“")
        
        return recommendations
```

## ğŸ“ˆ ç›£è¦–ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹

### wandbé€£æº

```python
# ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’wandbã«ãƒ­ã‚°
metrics = {
    "daily_scraped_count": 150,
    "data_quality_score": 85.5,
    "processing_time_seconds": 45.2
}

response = requests.post(
    f"{BASE_URL}/api/v1/wandb/log-metrics",
    json=metrics
)
```

### Grafana ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
- PostgreSQLãƒ¡ãƒˆãƒªã‚¯ã‚¹ç›£è¦–
- ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æˆåŠŸç‡
- ãƒ‡ãƒ¼ã‚¿å“è³ªã‚¹ã‚³ã‚¢
- API ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“

## ğŸ”§ ç®¡ç†ãƒ»ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹

### ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

```bash
# 30æ—¥ä»¥ä¸Šå¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
curl -X POST "http://<TrueNAS-IP>:8000/api/v1/data/cleanup?days=30"

# é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã®å‰Šé™¤
curl -X POST "http://<TrueNAS-IP>:8000/api/v1/data/deduplicate"
```

### ãƒ­ã‚°ç¢ºèª

```bash
# Airflowãƒ­ã‚°
kubectl logs -f deployment/airflow-scheduler -n data-platform

# APIãƒ­ã‚°
kubectl logs -f deployment/api -n data-platform

# PostgreSQLãƒ­ã‚°
kubectl logs -f deployment/postgres -n data-platform
```

### ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

```bash
# API ãƒ¬ãƒ—ãƒªã‚«æ•°å¤‰æ›´
kubectl scale deployment api --replicas=3 -n data-platform

# ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ç¢ºèª
kubectl top pods -n data-platform
```

## ğŸš¨ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œ

1. **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼**
   ```bash
   kubectl get pods -n data-platform
   kubectl describe pod <pod-name> -n data-platform
   ```

2. **Airflow DAG ãŒè¡¨ç¤ºã•ã‚Œãªã„**
   - DAGãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
   - Airflowãƒ­ã‚°ã‚’ç¢ºèª

3. **API ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒé…ã„**
   - Redisã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®çŠ¶æ…‹ç¢ºèª
   - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªã®æœ€é©åŒ–

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

1. **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹**
   ```sql
   CREATE INDEX CONCURRENTLY idx_scraped_images_alt_text 
   ON scraped_images USING gin(to_tsvector('english', alt_text));
   ```

2. **Redis ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š**
   - TTLèª¿æ•´
   - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–

3. **Kubernetes ãƒªã‚½ãƒ¼ã‚¹èª¿æ•´**
   - CPU/ãƒ¡ãƒ¢ãƒªãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ»ãƒªãƒŸãƒƒãƒˆ
   - HPA (Horizontal Pod Autoscaler) è¨­å®š

## ğŸ“š å‚è€ƒè³‡æ–™

- [Airflow Documentation](https://airflow.apache.org/docs/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [TrueNAS Scale Apps](https://www.truenas.com/docs/scale/)
- [wandb Documentation](https://docs.wandb.ai/)